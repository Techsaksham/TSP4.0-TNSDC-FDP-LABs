{
 "cells": [
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "077fa2b0-5920-4d5c-b9a0-3ced419252e7",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891153a8",
   "metadata": {},
   "source": [
    "# Edunet Foundation : Class Room Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75fa99a3",
   "metadata": {},
   "source": [
    "## Lab 4.4 Chatbot using Hugging Face Transformers, NLTK (Natural Language Toolkit)\n",
    "### Objective:\n",
    " To implement a simple chatbot using Hugging Face Transformers, NLTK (Natural Language Toolkit), and TextBlob, we'll create a basic conversational agent that can engage in a dialogue with users and perform some rudimentary natural language processing tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36afe1d7-ee35-4c4c-b135-b9f10ef204f0",
   "metadata": {},
   "source": [
    "#### Prerequisites\n",
    "Make sure you have Python installed on your system along with the necessary libraries. You can install the required libraries using pip:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68bf2881-f6ba-4e07-b604-5018c63d0355",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install transformers nltk textblob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7673c2-17db-4700-adf9-2850957a7a83",
   "metadata": {},
   "source": [
    "### Steps to Implement the Chatbot\n",
    "\n",
    "\n",
    "#### 1. Initialize Libraries and Import Modules\n",
    "First, import the necessary libraries and modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879af7fc-9c29-494c-bc83-b402e92b8938",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from textblob import TextBlob\n",
    "import random\n",
    "from transformers import pipeline\n",
    "from nltk.chat.util import Chat, reflections\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726da07f-d52f-4958-b9b9-c3014744d308",
   "metadata": {},
   "source": [
    "#### 2. Define the Chatbot Responses\n",
    "Create a list of patterns and responses for the chatbot using NLTKâ€™s Chat module. This module allows you to define patterns and corresponding responses in a simple format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160c63c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.chat.util import Chat, reflections\n",
    "\n",
    "def nltk_chatbot():\n",
    "    print(\"Hi! I'm your chatbot. You can ask me anything or say 'exit' to end the conversation.\")\n",
    "\n",
    "    # Define conversation pairs and reflections (how the bot should respond)\n",
    "    pairs = [\n",
    "        [\n",
    "            r\"my name is (.*)\",\n",
    "            [\"Hello %1, how can I help you today?\",]\n",
    "        ],\n",
    "        [\n",
    "            r\"what is your name?\",\n",
    "            [\"My name is Chatbot and I'm here to assist you.\",]\n",
    "        ],\n",
    "        [\n",
    "            r\"how are you?\",\n",
    "            [\"I'm doing well, thank you!\", \"I'm good, thanks for asking.\",]\n",
    "        ],\n",
    "        [\n",
    "            r\"exit\",\n",
    "            [\"Goodbye!\", \"See you later!\", \"Have a great day!\"]\n",
    "        ],\n",
    "        # Add more patterns and responses here\n",
    "    ]\n",
    "\n",
    "    # Create a Chat instance\n",
    "    chatbot = Chat(pairs, reflections)\n",
    "    \n",
    "    # Start chatting\n",
    "    chatbot.converse()\n",
    "\n",
    "# Call the function to start the chatbot\n",
    "nltk_chatbot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2190b94a",
   "metadata": {},
   "source": [
    "**textblob Bot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdf4a5e-7bf5-41ec-a542-a30edbea9e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define responses\n",
    "responses = {\n",
    "    'hi': ['Hello!', 'Hi there!', 'Hey!'],\n",
    "    'how are you': ['I\\'m good, thanks!', 'Doing well, thanks for asking.'],\n",
    "    'bye': ['Goodbye!', 'Bye!', 'See you later!'],\n",
    "    'default': ['Sorry, I didn\\'t understand that.', 'Could you please repeat that?']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5e1716",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to generate response\n",
    "def get_response(user_input):\n",
    "    blob = TextBlob(user_input.lower())\n",
    "    for word in blob.words:\n",
    "        if word in responses:\n",
    "            return random.choice(responses[word])\n",
    "    return random.choice(responses['default'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2938bc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chatting with the user\n",
    "print(\"Chatbot: Hello! How can I help you today?\")\n",
    "while True:\n",
    "    user_input = input(\"User: \").strip().lower()\n",
    "    if user_input == 'exit':\n",
    "        break\n",
    "    response = get_response(user_input)\n",
    "    print(f\"Chatbot: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8d71b3-e4e1-455d-971c-9afade3dbf47",
   "metadata": {},
   "source": [
    "####  Use Hugging Face Transformers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d1bcdc-f510-4071-acac-5a0f4a0dafc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install transformers torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc8d00fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\acer\\anaconda3\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForQuestionAnswering were not initialized from the model checkpoint at gpt2 and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "#pre-trained model\n",
    "chatbot = pipeline(\"question-answering\", model=\"gpt2\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa8eaff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: hi\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "h argument needs to be of type (SquadExample, dict)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m user_input\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexit\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mchatbot\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_return_sequences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatGPT: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenerated_text\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\pipelines\\question_answering.py:391\u001b[0m, in \u001b[0;36mQuestionAnsweringPipeline.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;124;03mAnswer the question(s) given as inputs by using the context(s).\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[38;5;124;03m    - **answer** (`str`) -- The answer to the question.\u001b[39;00m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    389\u001b[0m \u001b[38;5;66;03m# Convert inputs to features\u001b[39;00m\n\u001b[1;32m--> 391\u001b[0m examples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_args_parser(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    392\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(examples, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(examples) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    393\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(examples[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\pipelines\\question_answering.py:219\u001b[0m, in \u001b[0;36mQuestionAnsweringArgumentHandler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid arguments \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwargs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    218\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, item \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(inputs):\n\u001b[1;32m--> 219\u001b[0m     inputs[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m inputs\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\pipelines\\question_answering.py:172\u001b[0m, in \u001b[0;36mQuestionAnsweringArgumentHandler.normalize\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m    169\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` cannot be empty\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    171\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m QuestionAnsweringPipeline\u001b[38;5;241m.\u001b[39mcreate_sample(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mitem)\n\u001b[1;32m--> 172\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m argument needs to be of type (SquadExample, dict)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: h argument needs to be of type (SquadExample, dict)"
     ]
    }
   ],
   "source": [
    "# Chatting with the user\n",
    "while True:\n",
    "    user_input = input(\"User: \")\n",
    "    if user_input.lower() == 'exit':\n",
    "        break\n",
    "    response = chatbot(user_input, max_length=100, num_return_sequences=1)\n",
    "    print(f\"ChatGPT: {response[0]['generated_text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ede0e31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5092e2b51105455aa80ae93858376d96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acer\\anaconda3\\lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\acer\\.cache\\huggingface\\hub\\models--deepset--roberta-base-squad2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdb8aa80ccb043cc99b9639f4c9249af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/496M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27ad558e0b7444e79574ef5d1a2fad19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/79.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6132d7a5cb364893bea5d65639336e8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d412c8c01f3c420697abbd650370d24d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19a4183f3dc74a30adef5fdaadec2741",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/772 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: WHAT IS DIABETES?\n",
      "Chatbot: a chronic medical condition\n",
      "User: tell me more?\n",
      "Chatbot: insulin\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 13>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Chatting with the user\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m---> 13\u001b[0m     user_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mUser: \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m user_input\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexit\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m     15\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py:1075\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m   1071\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_allow_stdin:\n\u001b[0;32m   1072\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(\n\u001b[0;32m   1073\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1074\u001b[0m     )\n\u001b[1;32m-> 1075\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1076\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1077\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1078\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1079\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1080\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py:1120\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m   1117\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   1119\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[1;32m-> 1120\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1121\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1122\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load the lightweight question-answering model\n",
    "chatbot = pipeline(\"question-answering\", model=\"deepset/roberta-base-squad2\")\n",
    "\n",
    "\n",
    "# Example context for medical question-answering\n",
    "context = \"\"\"\n",
    "Diabetes is a chronic medical condition in which blood sugar (glucose) levels are higher than normal. It occurs either because the pancreas does not produce enough insulin or because cells do not respond to the insulin that is produced. Common symptoms include frequent urination, increased thirst, and increased hunger. Long-term complications include cardiovascular disease, stroke, kidney failure, foot ulcers, and damage to the eyes.\n",
    "\"\"\"\n",
    "\n",
    "# Chatting with the user\n",
    "while True:\n",
    "    user_input = input(\"User: \")\n",
    "    if user_input.lower() == 'exit':\n",
    "        break\n",
    "    response = chatbot(question=user_input, context=context)\n",
    "    print(f\"Chatbot: {response['answer']}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13baa4a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
